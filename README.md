# ğŸ§  RAG-1: Retrieval-Augmented Generation Chatbot

An end-to-end Retrieval-Augmented Generation (RAG) based AI chatbot that
leverages open-source LLMs and vector databases to provide context-aware
answers from multiple data sources.

------------------------------------------------------------------------

## ğŸš€ Project Overview

RAG-1 is a GenAI project that combines:

-   ğŸ” Document Retrieval (Vector Search)
-   ğŸ§  Open-source Large Language Models (LLMs)
-   ğŸ“š Multi-source data ingestion
-   âš¡ FastAPI / Streamlit based interface
-   ğŸ—‚ï¸ FAISS Vector Store

The system retrieves relevant chunks from documents and augments the LLM
prompt with contextual information before generating responses.

------------------------------------------------------------------------

## ğŸ—ï¸ Architecture

User Query\
â†“\
Embedding Generation\
â†“\
FAISS Vector Search\
â†“\
Relevant Context Retrieved\
â†“\
LLM (LLaMA2 / Open Source Model)\
â†“\
Final Context-Aware Response

------------------------------------------------------------------------

## ğŸ› ï¸ Tech Stack

-   Python 3.10+
-   LangChain
-   FAISS
-   HuggingFace Embeddings
-   Open-source LLM (LLaMA2 / Mistral etc.)
-   FastAPI / Streamlit
-   Uvicorn
-   dotenv

------------------------------------------------------------------------

## ğŸ“‚ Project Structure

    RAG-1/
    â”‚
    â”œâ”€â”€ app.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ .env
    â”œâ”€â”€ data/
    â”œâ”€â”€ embeddings/
    â”œâ”€â”€ vectorstore/
    â”œâ”€â”€ utils/
    â””â”€â”€ README.md

------------------------------------------------------------------------

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

``` bash
git clone https://github.com/abhikghosh2049/RAG-1.git
cd RAG-1
```

### 2ï¸âƒ£ Create Virtual Environment

``` bash
python -m venv venv
venv\Scripts\activate  # Windows
```

### 3ï¸âƒ£ Install Dependencies

``` bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Add Environment Variables

Create a `.env` file:

    OPENAI_API_KEY=your_key_here
    GROQ_API_KEY=your_key_here

### 5ï¸âƒ£ Run the Application

For FastAPI:

``` bash
uvicorn app:app --reload
```

OR for Streamlit:

``` bash
streamlit run app.py
```

------------------------------------------------------------------------

## âœ¨ Features

-   Multi-document ingestion
-   Chunking using RecursiveCharacterTextSplitter
-   FAISS similarity search
-   Open-source LLM integration
-   Context-aware responses
-   Scalable architecture

------------------------------------------------------------------------

## ğŸ“ˆ Future Improvements

-   Add memory support (conversation history)
-   Deploy on cloud (AWS / Render / Vercel)
-   Add authentication layer
-   Improve UI/UX
-   Add streaming responses

------------------------------------------------------------------------

## ğŸ§‘â€ğŸ’» Author

**Abhik Ghosh**\
AI/ML & Data Science Enthusiast\
GitHub: https://github.com/abhikghosh2049

------------------------------------------------------------------------

## ğŸ“œ License

This project is open-source and available under the MIT License.

------------------------------------------------------------------------

â­ If you found this project helpful, consider giving it a star!
